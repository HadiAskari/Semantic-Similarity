{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import urllib.request as requests\n",
    "from tqdm.auto import tqdm\n",
    "from nltk import tokenize\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import transformers\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import nltk\n",
    "from nltk import tokenize\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def openUrl(url):\n",
    "    return requests.urlopen(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_process_text(text):\n",
    "    text=text.lower()\n",
    "    splitter=re.compile(r'\\.\\s?')\n",
    "    reslist=splitter.split(text)\n",
    "    rez = []\n",
    "    for res in reslist:\n",
    "        res=res.replace('\\\\n', ' ')\n",
    "        res=res.replace(\">\",\"\")\n",
    "        res=res.replace(\"♪♪\",\"♪\")\n",
    "        res=res.replace(\"♪\",\"tune.\")\n",
    "        res=res.replace(\"(\",\"\")\n",
    "        res=res.replace(\")\",\"\")\n",
    "        res=res.replace(\"]\",\"\")\n",
    "        res=res.replace(\"[\",\"\")\n",
    "        res=res.replace(\",\",\"\")\n",
    "        res=res.replace(\"?\",\"\")\n",
    "        res=res.replace(\"!\",\"\")\n",
    "        res=res.replace(\"/\",\"\")\n",
    "        res=res.replace(\"\\'\",\"\")\n",
    "        res=res.replace(\"\\\"\",\"\")\n",
    "        res=res.replace(\"\\\\\",\"\")\n",
    "        rez.append(res)\n",
    "    final=[]\n",
    "    sent=[]\n",
    "    length=0\n",
    "    for item in rez:\n",
    "        length=length+len(item)\n",
    "        sent.append(item)\n",
    "        if length>100:\n",
    "            length=0\n",
    "            temp=' '.join(sent)\n",
    "            final.append(temp)\n",
    "            sent=[]\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    text=text.lower()\n",
    "    text=text.replace(\"(\", \"\")\n",
    "    text=text.replace(\")\", \"\")\n",
    "    text=text.replace(\";\", \"\")\n",
    "    text=text.replace(\",\", \"\")\n",
    "    text=text.replace(\"+\", \"\")\n",
    "    text=text.replace(\".\", \"\")\n",
    "    text=text.replace(\"&\", \"\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCC(filename): #get the closed captions and preprocess them into sentences\n",
    "    CC=[]\n",
    "    seg1=defaultdict(list)\n",
    "    cc1=[]\n",
    "    seg=[]\n",
    "\n",
    "    try:\n",
    "        asset_metadata = json.loads(openUrl('http://ac3448e420fce11eaaa4b0a458c10dab-684955813.us-east-1.elb.amazonaws.com/MafData/rs/db/mafdb/analysis/{}/ClosedCaptions?limit=100000'.format(filename)).read())\n",
    "        contentseg = json.loads(openUrl('http://ac3448e420fce11eaaa4b0a458c10dab-684955813.us-east-1.elb.amazonaws.com/MafData/rs/db/mafdb/analysis/{}/contentSegmentation'.format(filename)).read())\n",
    "\n",
    "\n",
    "        for i in range(len(contentseg['result'])):\n",
    "            if contentseg['result'][i]['segmentType'] == 'segment':\n",
    "                dic1={'startTime':contentseg['result'][i]['startTime'],\n",
    "                'endTime':contentseg['result'][i]['endTime'], 'ClosedCaption': ''}\n",
    "                seg.append(dic1)\n",
    "\n",
    "            if contentseg['result'][i]['segmentType'] == 'som_eom':\n",
    "                global_start=contentseg['result'][i]['startTime']\n",
    "\n",
    "        print(len(seg))\n",
    "\n",
    "        for i in range(len(asset_metadata['result'])):\n",
    "            temp=asset_metadata['result'][i]['text']\n",
    "            temp=temp.replace('-','')\n",
    "            cc1.append(temp)\n",
    "\n",
    "            startcaption=asset_metadata['result'][i]['startTime']+global_start\n",
    "            endcaption=asset_metadata['result'][i]['endTime']+global_start\n",
    "\n",
    "            temp1=[]\n",
    "\n",
    "            for j in range(len(seg)):\n",
    "\n",
    "                if startcaption >= seg[j]['startTime'] and endcaption <= seg[j]['endTime']:\n",
    "                    temp=asset_metadata['result'][i]['text']\n",
    "                    temp=temp.replace('-','')\n",
    "                    # print(seg[j])\n",
    "                    seg[j]['ClosedCaption']=seg[j]['ClosedCaption'] + ' ' + temp\n",
    "\n",
    "\n",
    "\n",
    "        string=' '.join([str(item) for item in cc1])\n",
    "        CC.append(string)\n",
    "        seg1[filename]=seg\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        CC.append('-')\n",
    "\n",
    "        #seg[j]['ClosedCaption'].append('-')\n",
    "    return seg1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getAdwords(Adwords_Path, Tier): #get the adwords with the childadwords appended\n",
    "\n",
    "    df_fullname=pd.read_excel(Tier)\n",
    "    df_fullname = df_fullname.fillna('')\n",
    "    df_fullname['New_Name']=df_fullname['Name']+ \" - \"+ df_fullname['Tier 1']+ \" \"+ df_fullname['Tier 2']+ \" \"+ df_fullname['Tier 3']+ \" \"+df_fullname['Tier 4']\n",
    "\n",
    "    df=pd.read_csv(Adwords_Path)\n",
    "    df_unique=df[['Name','Unique ID ']]\n",
    "    df_AllTiers=df[df['Important to NBCU']=='Y']\n",
    "    df_AllTiers=df_AllTiers['Name']\n",
    "    dftier1=df[df['Tier (1-4)']==1]\n",
    "    dftier1=dftier1['Name']\n",
    "    df=df[['Name', 'Tier 1 Parent']]\n",
    "\n",
    "    def combiner(dftier1, df ):\n",
    "        og=dftier1.to_list()\n",
    "        ogName=df['Name'].to_list()\n",
    "        Tier1Parent=df['Tier 1 Parent'].to_list()\n",
    "        final=defaultdict(list)\n",
    "        for i in range(len(ogName)):\n",
    "            for j in range(len(og)):\n",
    "                if og[j]==Tier1Parent[i]:\n",
    "                    final[og[j]].append(ogName[i])     \n",
    "\n",
    "        for k,v in final.items():\n",
    "            combined=\" \".join(v)\n",
    "            combined=combined.replace(k + \" \", \" \")\n",
    "            final[k]=combined\n",
    "            \n",
    "        return final\n",
    "\n",
    "    dic=combiner(dftier1, df)\n",
    "    dffinal=pd.DataFrame()\n",
    "\n",
    "    \n",
    "    listalltiers=df_AllTiers.to_list()\n",
    "    childadwords=[]\n",
    "    uniqueID=[]\n",
    "    for item in listalltiers:\n",
    "        temp=[]\n",
    "        for k,v in dic.items():\n",
    "            if k==item:\n",
    "                temp.append(v)\n",
    "        if len(temp)>0:\n",
    "            childadwords.append(temp)\n",
    "        if len(temp)==0:\n",
    "            childadwords.append(\" \")\n",
    "\n",
    "        new_temp=df_unique.loc[df['Name']==item]\n",
    "        uniqueID.append(new_temp['Unique ID '].values[0])\n",
    "                \n",
    "    for count, val in enumerate(childadwords):\n",
    "        combined=\" \".join(val)\n",
    "        childadwords[count]=combined\n",
    "\n",
    "\n",
    "\n",
    "    for count, val in enumerate(listalltiers):\n",
    "        newnamedf=df_fullname.loc[df_fullname['Name']==val]\n",
    "        newnamedf = newnamedf.fillna('')\n",
    "        try:\n",
    "            name=newnamedf['New_Name'].values[0]\n",
    "            name=name.strip()\n",
    "            listalltiers[count]=name\n",
    "        except:\n",
    "            print(val)\n",
    "            print(newnamedf['New_Name'])\n",
    "\n",
    "        \n",
    "\n",
    "    # print(listalltiers)\n",
    "\n",
    "    dffinal['Name']=listalltiers\n",
    "    dffinal['info']=childadwords \n",
    "    dffinal['UniqueID']=uniqueID\n",
    "\n",
    "\n",
    "\n",
    "    return dffinal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual Brands\n",
      "Series([], Name: New_Name, dtype: object)\n",
      "['Automotive - Automotive', 'Books and Literature - Books and Literature', 'Business and Finance - Business and Finance', 'Education - Education', 'Events and Attractions - Events and Attractions', 'Family and Relationships - Family and Relationships', 'Fine Art - Fine Art', 'Food & Drink - Food & Drink', 'Healthy Living - Healthy Living', 'Hobbies & Interests - Hobbies & Interests', 'Home & Garden - Home & Garden', 'Medical Health - Medical Health', 'Movies - Movies', 'Music and Audio - Music and Audio', 'Pets - Pets', 'Pop Culture - Pop Culture', 'Real Estate - Real Estate', 'Religion & Spirituality - Religion & Spirituality', 'Science - Science', 'Shopping - Shopping', 'Sports - Sports', 'Style & Fashion - Style & Fashion', 'Technology & Computing - Technology & Computing', 'Television - Television', 'Travel - Travel', 'Video Gaming - Video Gaming', 'Auto Body Styles - Automotive Auto Body Styles', 'Motorcycles - Automotive Motorcycles', 'Road-Side Assistance - Automotive Road-Side Assistance', 'Auto Parts - Automotive Auto Parts', 'Auto Repair - Automotive Auto Repair', 'Auto Shows - Automotive Auto Shows', 'Auto Rentals - Automotive Auto Rentals', 'College Education - Education College Education', 'Primary Education - Education Primary Education', 'Fashion Events - Events and Attractions Fashion Events', 'Malls & Shopping Centers - Events and Attractions Malls & Shopping Centers', 'Museums & Galleries - Events and Attractions Museums & Galleries', 'Outdoor Activities - Events and Attractions Outdoor Activities', 'Parks & Nature - Events and Attractions Parks & Nature', 'Awards Shows - Events and Attractions Awards Shows', 'Personal Celebrations & Life Events - Events and Attractions Personal Celebrations & Life Events', 'Religious Events - Events and Attractions Religious Events', 'Theater Venues and Events - Events and Attractions Theater Venues and Events', 'Zoos & Aquariums - Events and Attractions Zoos & Aquariums', 'Bars & Restaurants - Events and Attractions Bars & Restaurants', 'Casinos & Gambling - Events and Attractions Casinos & Gambling', 'Cinemas and Events - Events and Attractions Cinemas and Events', 'Comedy Events - Events and Attractions Comedy Events', 'Concerts & Music Events - Events and Attractions Concerts & Music Events', 'Dating - Family and Relationships Dating', 'Parenting - Family and Relationships Parenting', 'Single Life - Family and Relationships Single Life', 'Alcoholic Beverages - Food & Drink Alcoholic Beverages', 'World Cuisines - Food & Drink World Cuisines', 'Barbecues and Grilling - Food & Drink Barbecues and Grilling', 'Cooking - Food & Drink Cooking', 'Desserts and Baking - Food & Drink Desserts and Baking', 'Dining Out - Food & Drink Dining Out', 'Non-Alcoholic Beverages - Food & Drink Non-Alcoholic Beverages', 'Fitness and Exercise - Healthy Living Fitness and Exercise', 'Wellness - Healthy Living Wellness', 'Musical Instruments - Hobbies & Interests Musical Instruments', 'Games and Puzzles - Hobbies & Interests Games and Puzzles', 'Gardening - Home & Garden Gardening', 'Remodeling & Construction - Home & Garden Remodeling & Construction', 'Smart Home - Home & Garden Smart Home', 'Home Appliances - Home & Garden Home Appliances', 'Home Entertaining - Home & Garden Home Entertaining', 'Home Improvement - Home & Garden Home Improvement', 'Home Security - Home & Garden Home Security', 'Landscaping - Home & Garden Landscaping', 'Birds - Pets Birds', 'Cats - Pets Cats', 'Dogs - Pets Dogs', 'Large Animals - Pets Large Animals', 'Reptiles - Pets Reptiles', 'Apartments - Real Estate Apartments', 'Retail Property - Real Estate Retail Property', 'Hotel Properties - Real Estate Hotel Properties', 'Houses - Real Estate Houses', 'Land and Farms - Real Estate Land and Farms', 'Office Property - Real Estate Office Property', 'Space and Astronomy - Science Space and Astronomy', 'Flower Shopping - Shopping Flower Shopping', 'Grocery Shopping - Shopping Grocery Shopping', 'Holiday Shopping - Shopping Holiday Shopping', 'Household Supplies - Shopping Household Supplies', \"Children's Games and Toys - Shopping Children's Games and Toys\", 'Beauty - Style & Fashion Beauty', 'Consumer Electronics - Technology & Computing Consumer Electronics', 'Travel Accessories - Travel Travel Accessories', 'Travel Locations - Travel Travel Locations', 'Commercial Trucks - Automotive Auto Body Styles Commercial Trucks', 'Sedan - Automotive Auto Body Styles Sedan', 'Station Wagon - Automotive Auto Body Styles Station Wagon', 'SUV - Automotive Auto Body Styles SUV', 'Van - Automotive Auto Body Styles Van', 'Convertible - Automotive Auto Body Styles Convertible', 'Coupe - Automotive Auto Body Styles Coupe', 'Minivan - Automotive Auto Body Styles Minivan', 'Pickup Trucks - Automotive Auto Body Styles Pickup Trucks', 'Green Vehicles - Automotive Auto Type Green Vehicles', 'Luxury Cars - Automotive Auto Type Luxury Cars', 'Education industry - Business and Finance Industries Education industry', 'Entertainment Industry - Business and Finance Industries Entertainment Industry', 'Financial Industry - Business and Finance Industries Financial Industry', 'Food Industry - Business and Finance Industries Food Industry', 'Healthcare Industry - Business and Finance Industries Healthcare Industry', 'Hospitality Industry - Business and Finance Industries Hospitality Industry', 'Logistics and Transportation Industry - Business and Finance Industries Logistics and Transportation Industry', 'Media Industry - Business and Finance Industries Media Industry', 'Apparel Industry - Business and Finance Industries Apparel Industry', 'Retail Industry - Business and Finance Industries Retail Industry', 'Technology Industry - Business and Finance Industries Technology Industry', 'Telecommunications Industry - Business and Finance Industries Telecommunications Industry', 'Automotive Industry - Business and Finance Industries Automotive Industry', 'Aviation Industry - Business and Finance Industries Aviation Industry', 'Wedding - Events and Attractions Personal Celebrations & Life Events Wedding', 'Birthday - Events and Attractions Personal Celebrations & Life Events Birthday', 'Graduation - Events and Attractions Personal Celebrations & Life Events Graduation', 'Prom - Events and Attractions Personal Celebrations & Life Events Prom', 'Daycare and Pre-School - Family and Relationships Parenting Daycare and Pre-School', 'Board Games and Puzzles - Hobbies & Interests Games and Puzzles Board Games and Puzzles', 'Card Games - Hobbies & Interests Games and Puzzles Card Games', 'Hair Care - Style & Fashion Beauty Hair Care', 'Makeup and Accessories - Style & Fashion Beauty Makeup and Accessories', 'Nail Care - Style & Fashion Beauty Nail Care', 'Perfume and Fragrance - Style & Fashion Beauty Perfume and Fragrance', \"Women's Clothing - Style & Fashion Women's Fashion Women's Clothing\", \"Women's Shoes and Footwear - Style & Fashion Women's Fashion Women's Shoes and Footwear\", \"Men's Clothing - Style & Fashion Men's Fashion Men's Clothing\", 'Bath and Shower - Style & Fashion Personal Care Bath and Shower', 'Deodorant and Antiperspirant - Style & Fashion Personal Care Deodorant and Antiperspirant', 'Oral care - Style & Fashion Personal Care Oral care', 'Shaving - Style & Fashion Personal Care Shaving', 'Desktops - Technology & Computing Computing Desktops', 'Laptops - Technology & Computing Computing Laptops', 'Cameras and Camcorders - Technology & Computing Consumer Electronics Cameras and Camcorders', 'Smartphones - Technology & Computing Consumer Electronics Smartphones', 'Tablets and E-readers - Technology & Computing Consumer Electronics Tablets and E-readers', 'Africa Travel - Travel Travel Locations Africa Travel', 'Asia Travel - Travel Travel Locations Asia Travel', 'Australia and Oceania Travel - Travel Travel Locations Australia and Oceania Travel', 'Europe Travel - Travel Travel Locations Europe Travel', 'North America Travel - Travel Travel Locations North America Travel', 'Polar Travel - Travel Travel Locations Polar Travel', 'South America Travel - Travel Travel Locations South America Travel', 'Hotels and Motels - Travel Travel Type Hotels and Motels', 'Rail Travel - Travel Travel Type Rail Travel', 'Air Travel - Travel Travel Type Air Travel', 'Beach Travel - Travel Travel Type Beach Travel', 'Camping - Travel Travel Type Camping', 'Cruises - Travel Travel Type Cruises', 'Individual Brands', \"Women's Handbags and Wallets - Style & Fashion Women's Fashion Women's Accessories Women's Handbags and Wallets\", \"Women's Jewelry and Watches - Style & Fashion Women's Fashion Women's Accessories Women's Jewelry and Watches\", \"Women's Formal Wear - Style & Fashion Women's Fashion Women's Clothing Women's Formal Wear\", \"Men's Casual Wear - Style & Fashion Men's Fashion Men's Clothing Men's Casual Wear\", \"Men's Formal Wear - Style & Fashion Men's Fashion Men's Clothing Men's Formal Wear\"]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRelevance(filename, adwordpath):\n",
    "    model = SentenceTransformer('all-mpnet-base-v2')\n",
    "    captions=getCC(filename)\n",
    "    adworddf=getAdwords(adwordpath)\n",
    "\n",
    "    # print(captions['FILE_MAF_20210727T231032Z_GMO_00000000001650_01'][0]['ClosedCaption'])\n",
    "    adworddf['info']=adworddf['info'].apply(clean)\n",
    "    targetlist=adworddf['Name'].to_list()\n",
    "    targetlistchild=adworddf['Name']+adworddf['info']\n",
    "    uniqueIDlist=adworddf['UniqueID'].to_list()\n",
    "\n",
    "    CCsegments=[]\n",
    "    for i in range(len(captions[filename])):\n",
    "        cc=captions[filename][i]['ClosedCaption']\n",
    "        cc=new_process_text(cc)\n",
    "        CCsegments.append(cc)\n",
    "    \n",
    "    \n",
    "    result=[]\n",
    "    \n",
    "    for l in tqdm(range(len(CCsegments))):\n",
    "        if len(CCsegments[l])==0: \n",
    "            continue\n",
    "        emb1=model.encode(CCsegments[l]) #, convert_to_tensor=True)\n",
    "        emb2=model.encode(targetlistchild) #, convert_to_tensor=True)\n",
    "        cos_sim=util.cos_sim(emb1,emb2)\n",
    "\n",
    "\n",
    "        keywordd=[]\n",
    "        for k in range(cos_sim.shape[1]):\n",
    "            all_sentence_combinations=[]\n",
    "            for j in range(cos_sim.shape[0]):\n",
    "                all_sentence_combinations.append([cos_sim[j][k], j, k])\n",
    "            all_sentence_combinations = sorted(all_sentence_combinations, key=lambda x: x[0], reverse=True)\n",
    "            all_sentence_combinations = [ele for ele in all_sentence_combinations if ele[0] > 0.1]\n",
    "\n",
    "            \n",
    "            for ele in all_sentence_combinations:\n",
    "                uniqueID=uniqueIDlist[ele[2]]\n",
    "                keyword=targetlist[ele[2]]\n",
    "                relevance=ele[0].numpy().tolist()\n",
    "                relevance_clues=CCsegments[l][ele[1]]\n",
    "                d={}\n",
    "                d['uniqueID']=uniqueID\n",
    "                d['keyword']=keyword\n",
    "                d['relevance']=relevance\n",
    "                d['relevance_clues']=relevance_clues\n",
    "                keywordd.append(d)\n",
    "\n",
    "\n",
    "        segres={'offsetStartTime':captions[filename][l]['startTime'], 'offsetEndTime':captions[filename][l]['endTime'], \"keywords\": keywordd}\n",
    "        result.append(segres)\n",
    "\n",
    "    final = json.dumps(result)\n",
    "    print(final)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"-f\", \"--MAF_ID\",\n",
    "                    help=\"MAF ID of the file to generate the result for\")\n",
    "    parser.add_argument(\"-p\", \"--PathAdwords\", \n",
    "                    help=\"Path of Output Adwords File\")\n",
    "    parser.add_argument(\"-t\", \"--PathTiers\", \n",
    "                    help=\"Path of IAB Tiered File\")\n",
    "    parser.add_argument(\"-l\", \"--Link\", \n",
    "                    help=\"Link to call Comcast Endpoints\")\n",
    "    args=parser.parse_args()\n",
    "\n",
    "    file_name=args.MAF_ID\n",
    "    Adwords_Path=args.PathAdwords\n",
    "    tiers=args.PathTiers\n",
    "    link=args.Link\n",
    "\n",
    "    print(file_name)\n",
    "    print(Adwords_Path)\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID='FILE_MAF_20210727T231032Z_GMO_00000000001650_01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asset_metadata = json.loads(openUrl('http://ac3448e420fce11eaaa4b0a458c10dab-684955813.us-east-1.elb.amazonaws.com/MafData/rs/db/mafdb/analysis/{}/ClosedCaptions?limit=100000'.format(ID)).read())\n",
    "contentseg = json.loads(openUrl('http://ac3448e420fce11eaaa4b0a458c10dab-684955813.us-east-1.elb.amazonaws.com/MafData/rs/db/mafdb/analysis/{}/contentSegmentation'.format(ID)).read())\n",
    "print(asset_metadata)\n",
    "print(contentseg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getRelevance('FILE_MAF_20210727T231032Z_GMO_00000000001650_01','Final-NBCU-Contextual-IAB-Taxonomy-Mapping-2022-Copy.csv' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res=getCC('FILE_MAF_20210727T231032Z_GMO_00000000001650_01')\n",
    "print(res['FILE_MAF_20210727T231032Z_GMO_00000000001650_01'][0]['ClosedCaption'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              Name  \\\n",
      "0                          Automotive - Automotive   \n",
      "1      Books and Literature - Books and Literature   \n",
      "2      Business and Finance - Business and Finance   \n",
      "3                            Education - Education   \n",
      "4  Events and Attractions - Events and Attractions   \n",
      "\n",
      "                                                info UniqueID  \n",
      "0   Crossover Hatchback Microcar Off-Road Vehicle...        1  \n",
      "1   Art and Photography Books Biographies Childre...       42  \n",
      "2   Business Business Accounting & Finance Human ...       52  \n",
      "3   College  Primary  Adult  Private School Secon...      132  \n",
      "4   Fashion Events Malls & Shopping Centers Museu...      150  \n"
     ]
    }
   ],
   "source": [
    "res=getAdwords('Final-NBCU-Contextual-IAB-Taxonomy-Mapping-2022-Copy.csv','IAB_Tech_Lab_Content_Taxonomy_V2_Final_2017-11.xlsx')\n",
    "print(res.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getRelevance('FILE_MAF_20210727T231032Z_GMO_00000000001650_01')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4f8fa3e926face00369008f823e0a800506eaa9d6c726ba0fbe6c8d0f6896eaa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
