{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-15 03:09:25.792608: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import pickle \n",
    "import pandas as pd\n",
    "import spacy\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "import re\n",
    "import transformers\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import nltk\n",
    "from nltk import tokenize\n",
    "import pickle\n",
    "import urllib.request as requests\n",
    "import json\n",
    "import statistics\n",
    "import torch\n",
    "from collections import defaultdict\n",
    "import copy\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = SentenceTransformer('./sbert_test_mnr2_Tier1')\n",
    "\n",
    "df=pd.read_csv('../gmo_to_uniqueId.csv')\n",
    "materialID=df['lastRunJob'].to_list()\n",
    "\n",
    "# with open('PreProcessed_segmented.pkl', 'rb') as f:\n",
    "#     newmetalist=pickle.load(f)\n",
    "\n",
    "with open('../New_PreProcessed_segmented.pkl', 'rb') as f:\n",
    "    newnewmetalist=pickle.load(f)\n",
    "\n",
    "sampled_datadf=pd.read_csv(\"../Sampled_Adword_Labeled.csv\")\n",
    "\n",
    "#For Normal process with target labels only\n",
    "\n",
    "df1=pd.read_csv('ChildAdwordTargetDatabase.csv')\n",
    "target_dict=dict(zip(df1['Name'], df1.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    text=text.lower()\n",
    "    text=text.replace(\"(\", \"\")\n",
    "    text=text.replace(\")\", \"\")\n",
    "    text=text.replace(\";\", \"\")\n",
    "    text=text.replace(\",\", \"\")\n",
    "    text=text.replace(\"+\", \"\")\n",
    "    text=text.replace(\".\", \"\")\n",
    "    text=text.replace(\"&\", \"\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Name</th>\n",
       "      <th>info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Automotive</td>\n",
       "      <td>Automotive Crossover Hatchback Microcar Off-Ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Books and Literature</td>\n",
       "      <td>Books and Literature Art and Photography Books...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Business and Finance</td>\n",
       "      <td>Business and Finance Business Business Account...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Education</td>\n",
       "      <td>Education College Education Primary Education ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Events and Attractions</td>\n",
       "      <td>Events and Attractions Fashion Events Malls &amp; ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                    Name  \\\n",
       "0           0              Automotive   \n",
       "1           1    Books and Literature   \n",
       "2           2    Business and Finance   \n",
       "3           3               Education   \n",
       "4           4  Events and Attractions   \n",
       "\n",
       "                                                info  \n",
       "0  Automotive Crossover Hatchback Microcar Off-Ro...  \n",
       "1  Books and Literature Art and Photography Books...  \n",
       "2  Business and Finance Business Business Account...  \n",
       "3  Education College Education Primary Education ...  \n",
       "4  Events and Attractions Fashion Events Malls & ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df1['Combined']=df1['Name'] #+' '+df1['info']\n",
    "# df1['Combined1']=df1['Name'] +' '+df1['info']\n",
    "# df1['Combined1'].apply(clean)\n",
    "# df1['Combined1'].apply(process_text)\n",
    "# df1['Combined'].apply(clean)\n",
    "\n",
    "df1['info']=df1['info'].apply(clean)\n",
    "#df1['info']=df1['info'].apply(process_text)\n",
    "targetlist=df1['Name'].to_list()\n",
    "# targetlistcalc=df1['Combined1'].to_list()\n",
    "targetlistchild=df1['info']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'AdwordLabeledDatabase.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/mnt/data0/haskari/Comcast/Fine-Tuning/Testing_NRS_Top1_Regular.ipynb Cell 6'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bsohrab.idav.ucdavis.edu/mnt/data0/haskari/Comcast/Fine-Tuning/Testing_NRS_Top1_Regular.ipynb#ch0000006vscode-remote?line=0'>1</a>\u001b[0m truthdatadf\u001b[39m=\u001b[39mpd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m'\u001b[39;49m\u001b[39mAdwordLabeledDatabase.csv\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bsohrab.idav.ucdavis.edu/mnt/data0/haskari/Comcast/Fine-Tuning/Testing_NRS_Top1_Regular.ipynb#ch0000006vscode-remote?line=1'>2</a>\u001b[0m truthdatadf\u001b[39m.\u001b[39mhead()\n",
      "File \u001b[0;32m~/.conda/envs/Comcast/lib/python3.10/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/haskari/.conda/envs/Comcast/lib/python3.10/site-packages/pandas/util/_decorators.py?line=304'>305</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    <a href='file:///home/haskari/.conda/envs/Comcast/lib/python3.10/site-packages/pandas/util/_decorators.py?line=305'>306</a>\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    <a href='file:///home/haskari/.conda/envs/Comcast/lib/python3.10/site-packages/pandas/util/_decorators.py?line=306'>307</a>\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[1;32m    <a href='file:///home/haskari/.conda/envs/Comcast/lib/python3.10/site-packages/pandas/util/_decorators.py?line=307'>308</a>\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    <a href='file:///home/haskari/.conda/envs/Comcast/lib/python3.10/site-packages/pandas/util/_decorators.py?line=308'>309</a>\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[1;32m    <a href='file:///home/haskari/.conda/envs/Comcast/lib/python3.10/site-packages/pandas/util/_decorators.py?line=309'>310</a>\u001b[0m     )\n\u001b[0;32m--> <a href='file:///home/haskari/.conda/envs/Comcast/lib/python3.10/site-packages/pandas/util/_decorators.py?line=310'>311</a>\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/Comcast/lib/python3.10/site-packages/pandas/io/parsers/readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    <a href='file:///home/haskari/.conda/envs/Comcast/lib/python3.10/site-packages/pandas/io/parsers/readers.py?line=664'>665</a>\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    <a href='file:///home/haskari/.conda/envs/Comcast/lib/python3.10/site-packages/pandas/io/parsers/readers.py?line=665'>666</a>\u001b[0m     dialect,\n\u001b[1;32m    <a href='file:///home/haskari/.conda/envs/Comcast/lib/python3.10/site-packages/pandas/io/parsers/readers.py?line=666'>667</a>\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/haskari/.conda/envs/Comcast/lib/python3.10/site-packages/pandas/io/parsers/readers.py?line=675'>676</a>\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m    <a href='file:///home/haskari/.conda/envs/Comcast/lib/python3.10/site-packages/pandas/io/parsers/readers.py?line=676'>677</a>\u001b[0m )\n\u001b[1;32m    <a href='file:///home/haskari/.conda/envs/Comcast/lib/python3.10/site-packages/pandas/io/parsers/readers.py?line=677'>678</a>\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> <a href='file:///home/haskari/.conda/envs/Comcast/lib/python3.10/site-packages/pandas/io/parsers/readers.py?line=679'>680</a>\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/.conda/envs/Comcast/lib/python3.10/site-packages/pandas/io/parsers/readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    <a href='file:///home/haskari/.conda/envs/Comcast/lib/python3.10/site-packages/pandas/io/parsers/readers.py?line=571'>572</a>\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    <a href='file:///home/haskari/.conda/envs/Comcast/lib/python3.10/site-packages/pandas/io/parsers/readers.py?line=573'>574</a>\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/haskari/.conda/envs/Comcast/lib/python3.10/site-packages/pandas/io/parsers/readers.py?line=574'>575</a>\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    <a href='file:///home/haskari/.conda/envs/Comcast/lib/python3.10/site-packages/pandas/io/parsers/readers.py?line=576'>577</a>\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    <a href='file:///home/haskari/.conda/envs/Comcast/lib/python3.10/site-packages/pandas/io/parsers/readers.py?line=577'>578</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/.conda/envs/Comcast/lib/python3.10/site-packages/pandas/io/parsers/readers.py:934\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    <a href='file:///home/haskari/.conda/envs/Comcast/lib/python3.10/site-packages/pandas/io/parsers/readers.py?line=930'>931</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    <a href='file:///home/haskari/.conda/envs/Comcast/lib/python3.10/site-packages/pandas/io/parsers/readers.py?line=932'>933</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/haskari/.conda/envs/Comcast/lib/python3.10/site-packages/pandas/io/parsers/readers.py?line=933'>934</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m~/.conda/envs/Comcast/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1218\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   <a href='file:///home/haskari/.conda/envs/Comcast/lib/python3.10/site-packages/pandas/io/parsers/readers.py?line=1213'>1214</a>\u001b[0m     mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   <a href='file:///home/haskari/.conda/envs/Comcast/lib/python3.10/site-packages/pandas/io/parsers/readers.py?line=1214'>1215</a>\u001b[0m \u001b[39m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/haskari/.conda/envs/Comcast/lib/python3.10/site-packages/pandas/io/parsers/readers.py?line=1215'>1216</a>\u001b[0m \u001b[39m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/haskari/.conda/envs/Comcast/lib/python3.10/site-packages/pandas/io/parsers/readers.py?line=1216'>1217</a>\u001b[0m \u001b[39m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[0;32m-> <a href='file:///home/haskari/.conda/envs/Comcast/lib/python3.10/site-packages/pandas/io/parsers/readers.py?line=1217'>1218</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(  \u001b[39m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[1;32m   <a href='file:///home/haskari/.conda/envs/Comcast/lib/python3.10/site-packages/pandas/io/parsers/readers.py?line=1218'>1219</a>\u001b[0m     f,\n\u001b[1;32m   <a href='file:///home/haskari/.conda/envs/Comcast/lib/python3.10/site-packages/pandas/io/parsers/readers.py?line=1219'>1220</a>\u001b[0m     mode,\n\u001b[1;32m   <a href='file:///home/haskari/.conda/envs/Comcast/lib/python3.10/site-packages/pandas/io/parsers/readers.py?line=1220'>1221</a>\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   <a href='file:///home/haskari/.conda/envs/Comcast/lib/python3.10/site-packages/pandas/io/parsers/readers.py?line=1221'>1222</a>\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   <a href='file:///home/haskari/.conda/envs/Comcast/lib/python3.10/site-packages/pandas/io/parsers/readers.py?line=1222'>1223</a>\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   <a href='file:///home/haskari/.conda/envs/Comcast/lib/python3.10/site-packages/pandas/io/parsers/readers.py?line=1223'>1224</a>\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   <a href='file:///home/haskari/.conda/envs/Comcast/lib/python3.10/site-packages/pandas/io/parsers/readers.py?line=1224'>1225</a>\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   <a href='file:///home/haskari/.conda/envs/Comcast/lib/python3.10/site-packages/pandas/io/parsers/readers.py?line=1225'>1226</a>\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   <a href='file:///home/haskari/.conda/envs/Comcast/lib/python3.10/site-packages/pandas/io/parsers/readers.py?line=1226'>1227</a>\u001b[0m )\n\u001b[1;32m   <a href='file:///home/haskari/.conda/envs/Comcast/lib/python3.10/site-packages/pandas/io/parsers/readers.py?line=1227'>1228</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/haskari/.conda/envs/Comcast/lib/python3.10/site-packages/pandas/io/parsers/readers.py?line=1228'>1229</a>\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/.conda/envs/Comcast/lib/python3.10/site-packages/pandas/io/common.py:786\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    <a href='file:///home/haskari/.conda/envs/Comcast/lib/python3.10/site-packages/pandas/io/common.py?line=780'>781</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    <a href='file:///home/haskari/.conda/envs/Comcast/lib/python3.10/site-packages/pandas/io/common.py?line=781'>782</a>\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/haskari/.conda/envs/Comcast/lib/python3.10/site-packages/pandas/io/common.py?line=782'>783</a>\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/haskari/.conda/envs/Comcast/lib/python3.10/site-packages/pandas/io/common.py?line=783'>784</a>\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    <a href='file:///home/haskari/.conda/envs/Comcast/lib/python3.10/site-packages/pandas/io/common.py?line=784'>785</a>\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/haskari/.conda/envs/Comcast/lib/python3.10/site-packages/pandas/io/common.py?line=785'>786</a>\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    <a href='file:///home/haskari/.conda/envs/Comcast/lib/python3.10/site-packages/pandas/io/common.py?line=786'>787</a>\u001b[0m             handle,\n\u001b[1;32m    <a href='file:///home/haskari/.conda/envs/Comcast/lib/python3.10/site-packages/pandas/io/common.py?line=787'>788</a>\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    <a href='file:///home/haskari/.conda/envs/Comcast/lib/python3.10/site-packages/pandas/io/common.py?line=788'>789</a>\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    <a href='file:///home/haskari/.conda/envs/Comcast/lib/python3.10/site-packages/pandas/io/common.py?line=789'>790</a>\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    <a href='file:///home/haskari/.conda/envs/Comcast/lib/python3.10/site-packages/pandas/io/common.py?line=790'>791</a>\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    <a href='file:///home/haskari/.conda/envs/Comcast/lib/python3.10/site-packages/pandas/io/common.py?line=791'>792</a>\u001b[0m         )\n\u001b[1;32m    <a href='file:///home/haskari/.conda/envs/Comcast/lib/python3.10/site-packages/pandas/io/common.py?line=792'>793</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/haskari/.conda/envs/Comcast/lib/python3.10/site-packages/pandas/io/common.py?line=793'>794</a>\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/haskari/.conda/envs/Comcast/lib/python3.10/site-packages/pandas/io/common.py?line=794'>795</a>\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'AdwordLabeledDatabase.csv'"
     ]
    }
   ],
   "source": [
    "truthdatadf=pd.read_csv('AdwordLabeledDatabase.csv')\n",
    "truthdatadf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getadword(episode, truthdatadf):\n",
    "    for i in range(len(truthdatadf.lastRunJob)):\n",
    "        if episode == truthdatadf.lastRunJob[i]:\n",
    "            return truthdatadf.adword[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp=targetlistcalc[27]\n",
    "# temp=temp.replace('*News business use case needs to be scoped by NBCU - priority TBD', '')\n",
    "# targetlistcalc[27]=temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>materialId</th>\n",
       "      <th>lastRunJob</th>\n",
       "      <th>materialtitle</th>\n",
       "      <th>seriestitle</th>\n",
       "      <th>AssetCC</th>\n",
       "      <th>adword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>665</td>\n",
       "      <td>665</td>\n",
       "      <td>GMO_00000000040741_01</td>\n",
       "      <td>FILE_MAF_20210731T020535Z_GMO_00000000040741_01</td>\n",
       "      <td>I KNEW YOU WHEN</td>\n",
       "      <td>friday night lights</td>\n",
       "      <td>LKS, IS IS SLAMMIN' SAMMY MEADE,\\nFO [radio]\\n...</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8244</td>\n",
       "      <td>8244</td>\n",
       "      <td>GMO_00000000370441_01</td>\n",
       "      <td>FILE_MAF_20220215T090159Z_GMO_00000000370441_01</td>\n",
       "      <td>Make Up or Break Up?</td>\n",
       "      <td>total bellas</td>\n",
       "      <td>&gt;&gt; NIKKI: Yeah! Welcome to Paris! Tonight on t...</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>678</td>\n",
       "      <td>678</td>\n",
       "      <td>GMO_00000000039091_01</td>\n",
       "      <td>FILE_MAF_20220213T121447Z_GMO_00000000039091_01</td>\n",
       "      <td>HOMECOMING (EDITED)</td>\n",
       "      <td>friday night lights</td>\n",
       "      <td>What's after\\nhigh school, Brian? Me and Mack ...</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>777</td>\n",
       "      <td>777</td>\n",
       "      <td>GMO_00000000039094_01</td>\n",
       "      <td>FILE_MAF_20220213T173625Z_GMO_00000000039094_01</td>\n",
       "      <td>NEVERMIND (EDITED)</td>\n",
       "      <td>friday night lights</td>\n",
       "      <td>Here's to God in ten years from now, Street, g...</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>679</td>\n",
       "      <td>679</td>\n",
       "      <td>GMO_00000000039095_01</td>\n",
       "      <td>FILE_MAF_20220213T173619Z_GMO_00000000039095_01</td>\n",
       "      <td>WHAT TO DO WHILE YOU'RE WAITING (EDITED)</td>\n",
       "      <td>friday night lights</td>\n",
       "      <td>Dad? You're home! Hello, Brian. Waverly? Damn,...</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0             materialId  \\\n",
       "0           665         665  GMO_00000000040741_01   \n",
       "1          8244        8244  GMO_00000000370441_01   \n",
       "2           678         678  GMO_00000000039091_01   \n",
       "3           777         777  GMO_00000000039094_01   \n",
       "4           679         679  GMO_00000000039095_01   \n",
       "\n",
       "                                        lastRunJob  \\\n",
       "0  FILE_MAF_20210731T020535Z_GMO_00000000040741_01   \n",
       "1  FILE_MAF_20220215T090159Z_GMO_00000000370441_01   \n",
       "2  FILE_MAF_20220213T121447Z_GMO_00000000039091_01   \n",
       "3  FILE_MAF_20220213T173625Z_GMO_00000000039094_01   \n",
       "4  FILE_MAF_20220213T173619Z_GMO_00000000039095_01   \n",
       "\n",
       "                              materialtitle          seriestitle  \\\n",
       "0                           I KNEW YOU WHEN  friday night lights   \n",
       "1                      Make Up or Break Up?         total bellas   \n",
       "2                       HOMECOMING (EDITED)  friday night lights   \n",
       "3                        NEVERMIND (EDITED)  friday night lights   \n",
       "4  WHAT TO DO WHILE YOU'RE WAITING (EDITED)  friday night lights   \n",
       "\n",
       "                                             AssetCC  adword  \n",
       "0  LKS, IS IS SLAMMIN' SAMMY MEADE,\\nFO [radio]\\n...  Sports  \n",
       "1  >> NIKKI: Yeah! Welcome to Paris! Tonight on t...  Sports  \n",
       "2  What's after\\nhigh school, Brian? Me and Mack ...  Sports  \n",
       "3  Here's to God in ten years from now, Street, g...  Sports  \n",
       "4  Dad? You're home! Hello, Brian. Waverly? Damn,...  Sports  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_datadf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "listofepisodes=sampled_datadf['lastRunJob'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#listofepisodes=['FILE_MAF_20220211T205601Z_GMO_00000000001313_01', 'FILE_MAF_20220211T205607Z_GMO_00000000001534_01', 'FILE_MAF_20210727T231031Z_GMO_00000000001577_01' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keydict(dataframe, targetlist):\n",
    "    d=defaultdict(list)\n",
    "    for target in targetlist:\n",
    "        minidf=dataframe.loc[dataframe['adword']==target]\n",
    "        minilist=minidf['lastRunJob'].to_list()\n",
    "        d[target]=minilist\n",
    "    \n",
    "    return d\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetkey_filelist=keydict(sampled_datadf, targetlist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #NRS bulk with top 1 save to file regular\n",
    "# dict_to_save=defaultdict(list)\n",
    "# for target in tqdm(targetlist):\n",
    "#     scores=[]\n",
    "#     for ep in tqdm(listofepisodes):\n",
    "#         index=materialID.index(ep)\n",
    "#         groundtruth=getadword(ep,truthdatadf)\n",
    "#         # if groundtruth in target_dict:\n",
    "#         #         x=target_dict[groundtruth]\n",
    "#         x=target_dict[target]\n",
    "#         #print(groundtruth)\n",
    "#         print(x)\n",
    "#         segmentscore=[]\n",
    "#         for i in range(len(newmetalist[index])):\n",
    "#             if len(newmetalist[index][i])==0:\n",
    "#                 continue\n",
    "#             emb1=model.encode(newmetalist[index][i]) #, convert_to_tensor=True)\n",
    "#             emb2=model.encode(targetlist) #, convert_to_tensor=True)\n",
    "#             cos_sim=util.cos_sim(emb1,emb2)\n",
    "\n",
    "#             #For OG Class\n",
    "#             MaxAggregation = {}\n",
    "#             for i in range(cos_sim.shape[1]):\n",
    "#                 all_sentence_combinations=[]\n",
    "#                 for j in range(cos_sim.shape[0]):\n",
    "#                     all_sentence_combinations.append([cos_sim[j][i], j, i])\n",
    "#                 all_sentence_combinations = sorted(all_sentence_combinations, key=lambda x: x[0], reverse=True)\n",
    "#                 MaxAggregation[i]=all_sentence_combinations[0]\n",
    "                \n",
    "\n",
    "#             segmentscore.append(MaxAggregation[x][0])\n",
    "\n",
    "            \n",
    "                    \n",
    "#         avg=(sum(segmentscore)/len(segmentscore))\n",
    "#         scores.append(avg)\n",
    "        \n",
    "#     print(scores)\n",
    "#     dict_to_save[target]=scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('NRS_top1_regular.pkl', 'wb') as f:\n",
    "#     pickle.dump(dict_to_save, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('NRS_top1_regular.pkl', 'rb') as f:\n",
    "#     NRS_dict=pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_key(val):\n",
    "    for key, value in target_dict.items():\n",
    "         if val == value:\n",
    "             return key\n",
    " \n",
    "    return \"key doesn't exist\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dad=[]\n",
    "for i in range(len(newnewmetalist)):\n",
    "    mom=[]\n",
    "    for j in range(len(newnewmetalist[i])):\n",
    "        if len(newnewmetalist[i][j])==0:\n",
    "            continue\n",
    "        mom.append(newnewmetalist[i][j])\n",
    "    dad.append(mom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' just wanted to tell you that i appreciate you patching things up with him'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dad[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' just wanted to tell you that i appreciate you patching things up with him'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newnewmetalist[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84744ef0845749249edb3a8f2d6377c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "288012f1afd848dd91acd7578ff0443f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b54cb2b93fc43deb9fc54e7aa091cb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b2a62cf11704cd9b090a1494de1a7d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48cfc64625774035824498d039039eb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e3d6bff47914b0b9d69dda153988350",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8123da26bcf487cbe360ebf62ae25d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5b388082b604f9f963645beeebc70f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7add532b2b20490e82c37377dfbb1b79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7c43f0355a649ffb5f150d2d1040621",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02515c0964784a45a52f8e4d625bc4f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ebb882c40684c50bb5f8795f458ad55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7e08be006214467a4b0d8f64e6bdba5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce69166c5e7443a3a43e43193447e299",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cceee44ebd864617883d7924a1116d93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0c611a89f4140959fdb9451036fdc72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47ea7b27f97243ea856651c231de0117",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f45625873e14a4ebced843e920b8748",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1ac61f890414ad9b73022f471121587",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fa2fb25a2424599a363c49b39de794d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f10c9722651f45fe9cf505e5f992352b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Relevance calculation per episode top1\n",
    "dictofrelevance=copy.deepcopy(targetkey_filelist)\n",
    "for key, value in tqdm(targetkey_filelist.items()): #for each IAB Label\n",
    "    if len(targetkey_filelist[key])==0:\n",
    "        continue\n",
    "    for i in tqdm(range(len(targetkey_filelist[key]))): #for each File\n",
    "        index=materialID.index(targetkey_filelist[key][i])\n",
    "        x=target_dict[key] #Index of the target label\n",
    "        MaxAggregation=defaultdict(list)\n",
    "\n",
    "        for l in range(len(dad[index])): #For each Segment\n",
    "            # print(len(newmetalist[index]))\n",
    "            if len(dad[index][l])==0: \n",
    "                continue\n",
    "            emb1=model.encode(dad[index][l]) #, convert_to_tensor=True)\n",
    "            emb2=model.encode(targetlistchild) #, convert_to_tensor=True)\n",
    "            cos_sim=util.cos_sim(emb1,emb2)\n",
    "\n",
    "        #Add all pairs to a list with their cosine similarity score\n",
    "        \n",
    "            for k in range(cos_sim.shape[1]):\n",
    "                all_sentence_combinations=[]\n",
    "                for j in range(cos_sim.shape[0]):\n",
    "                    all_sentence_combinations.append([cos_sim[j][k], j, k])\n",
    "                all_sentence_combinations = sorted(all_sentence_combinations, key=lambda x: x[0], reverse=True)\n",
    "                MaxAggregation[k].append(all_sentence_combinations[0])\n",
    "    \n",
    "     \n",
    "        dictofrelevance[key][i]={dictofrelevance[key][i]:MaxAggregation}\n",
    "     \n",
    "\n",
    "with open('Relevance_Top1_ChildAdword.pkl', 'wb') as f:\n",
    "    pickle.dump(dictofrelevance, f)   \n",
    " \n",
    "        #RS and NRS for OG Class\n",
    "\n",
    "        # RSlist=MaxAggregation[x]\n",
    "        # score=[]\n",
    "        # for s in RSlist:\n",
    "        #     score.append(s[0])\n",
    "\n",
    "        # rs=sum(score)/len(score)\n",
    "\n",
    "        # NRSlist=NRS_dict[key]\n",
    "        # nrsdenom=sum(NRSlist)-rs/len(NRSlist)\n",
    "\n",
    "        # NRS=rs/nrsdenom\n",
    "\n",
    "        \n",
    "        # #RS and ClassPredicted for Predicted Class\n",
    "\n",
    "        # order=[]\n",
    "        # for key in MaxAggregation.keys():\n",
    "        #     l=MaxAggregation[key]\n",
    "        #     summ=[]\n",
    "        #     for val in l:\n",
    "        #         summ.append(val[0])\n",
    "        #     order.append(sum(summ))\n",
    "        \n",
    "        \n",
    "        # max_val=max(order)\n",
    "        # max_index=order.index(max_val)\n",
    "        # ClassPredicted=get_key(max_index)\n",
    "\n",
    "        # RSlistss=MaxAggregation[max_index]\n",
    "        # scoress=[]\n",
    "        # for s in RSlistss:\n",
    "        #     scoress.append(s[0])\n",
    "\n",
    "        # RS_CP=sum(scoress)/len(scoress)\n",
    "\n",
    "        # d={targetkey_filelist[key][i]:{'NRS': NRS, \"Class_Predicted\": ClassPredicted, \"RS_CP\": RS_CP, \"RS_OG\": rs }}\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Relevance_Top1_ChildAdword.pkl', 'rb') as f:\n",
    "     Relevance_dict=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Relevance_dict['Automotive'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Def Top1 Agg\n",
    "def segmentcombiner(dic): #for segments to final dic of relevance scores\n",
    "    dic1=copy.deepcopy(dic)\n",
    "    filename=list(dic1.keys())[0]\n",
    "    defdict=dic1[filename]\n",
    "    for k,v in defdict.items():\n",
    "        RSlist=defdict[k]\n",
    "        score=[]\n",
    "        for s in RSlist:\n",
    "            score.append(s[0])\n",
    "\n",
    "        rs=sum(score)/len(score)\n",
    "        defdict[k]=rs\n",
    "    d={filename:defdict}\n",
    "    return d\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Def Top3 and Harm Agg\n",
    "# def segmentcombinertop3Harm(dic): #for segments to final dic of relevance scores\n",
    "#     dic1=copy.deepcopy(dic)\n",
    "#     filename=list(dic1.keys())[0]\n",
    "#     defdict=dic1[filename]\n",
    "#     for k,v in defdict.items():\n",
    "#         RSlist=defdict[k][0]\n",
    "#         score=[]\n",
    "#         for s in RSlist:\n",
    "#             score.append(s[0])\n",
    "\n",
    "#         rs=sum(score)/len(score)\n",
    "#         defdict[k]=rs\n",
    "#     d={filename:defdict}\n",
    "#     return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(segmentcombiner(Relevance_dict_top3['Automotive'][18]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('Relevance_regular.pkl', 'rb') as f:\n",
    "#      Relevance_dict=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82876c0ede10420ca3d2ab5ba039ccb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc9c6d838eab45cf9080bc5a10fa1692",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04230f982d3944289cedd459c3c89615",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7acdc19ebdd4529aa0152c57a78ae03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(NRS(Relevance_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Def NRS for top1 \n",
    "def NRS(dict):\n",
    "    d={}\n",
    "    for k,v in tqdm(dict.items()):#for each label\n",
    "        if len(dict[k]) == 0:\n",
    "            continue\n",
    "        d1={}\n",
    "        for target in tqdm(targetlist): #for each topic\n",
    "            scoreforfiles=[]\n",
    "            if len(dict[target]) == 0:\n",
    "                continue\n",
    "            for i in range(len(dict[k])): #for each file in label\n",
    "                x=target_dict[target]\n",
    "                combinedsegments=segmentcombiner(dict[k][i])\n",
    "                key=list(combinedsegments.keys())[0]\n",
    "                scoreforfiles.append(float(combinedsegments[key][x])) #combine segments \n",
    "            avg=sum(scoreforfiles)/len(scoreforfiles)\n",
    "            d1[target]=avg\n",
    "        d[k]=d1\n",
    "\n",
    "    finaldict={}\n",
    "    for k,v in d.items():\n",
    "        numerator=d[k][k]\n",
    "        denominator=[]\n",
    "        for kk,vv in d.items():\n",
    "            denominator.append(d[kk][k])\n",
    "        avgdenominator=(sum(denominator)-numerator)/(len(denominator)-1)\n",
    "        NRS=numerator/avgdenominator\n",
    "        finaldict[k]=NRS\n",
    "    print(finaldict)\n",
    "\n",
    "\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(RSMetrics(Relevance_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Def RS at 0.15, 0.20, 0.35 and Mean RS \n",
    "def RSMetrics(dict):\n",
    "    d={}\n",
    "    for k,v in tqdm(dict.items()): #for each label\n",
    "        if len(dict[k]) == 0:\n",
    "            continue\n",
    "        scoreforfiles=[]\n",
    "        for i in range(len(dict[k])): #for each file in label\n",
    "            x=target_dict[k]\n",
    "            combinedsegments=segmentcombiner(dict[k][i])\n",
    "            key=list(combinedsegments.keys())[0]\n",
    "            scoreforfiles.append(round(float(combinedsegments[key][x]),2))\n",
    "        rs15=[]\n",
    "        rs20=[]\n",
    "        rs35=[]\n",
    "        for item in scoreforfiles:\n",
    "            if item >= 0.15:\n",
    "                rs15.append(item)\n",
    "            if item >= 0.20:\n",
    "                rs20.append(item)\n",
    "            if item >= 0.35:\n",
    "                rs35.append(item)\n",
    "\n",
    "        RS15=(len(rs15)/len(scoreforfiles))*100\n",
    "        RS20=(len(rs20)/len(scoreforfiles))*100\n",
    "        RS35=(len(rs35)/len(scoreforfiles))*100\n",
    "        d1={\"RS15\":RS15, \"RS20\": RS20, \"RS35\": RS35}\n",
    "        d[k]=d1\n",
    "    \n",
    "    return d\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Relevance_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/mnt/data0/haskari/Comcast/Fine-Tuning/Testing_NRS_Top1_Regular.ipynb Cell 34'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bsohrab.idav.ucdavis.edu/mnt/data0/haskari/Comcast/Fine-Tuning/Testing_NRS_Top1_Regular.ipynb#ch0000037vscode-remote?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(Prediction(Relevance_dict))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Relevance_dict' is not defined"
     ]
    }
   ],
   "source": [
    "print(Prediction(Relevance_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Def Predicted Class and RS of Class\n",
    "def Prediction(dict):\n",
    "    d={}\n",
    "    for k,v in tqdm(dict.items()): #for each label\n",
    "        if len(dict[k]) == 0:\n",
    "            continue\n",
    "        d1={}\n",
    "        for i in range(len(dict[k])): #for each file in label\n",
    "            combinedsegments=segmentcombiner(dict[k][i])\n",
    "            key=list(combinedsegments.keys())[0]\n",
    "            order=[]\n",
    "            for kk in combinedsegments[key].keys():\n",
    "                l=combinedsegments[key][kk]\n",
    "                order.append(l)\n",
    "            max_val=max(order)\n",
    "            max_index=order.index(max_val)\n",
    "            ClassPredicted=get_key(max_index)\n",
    "            RS_CP=combinedsegments[key][max_index]\n",
    "            d2={'ClassPredicted': ClassPredicted, 'RS_CP': RS_CP }\n",
    "            d1[key]=d2\n",
    "        d[k]=d1\n",
    "\n",
    "    return d\n",
    "\n",
    "            # \n",
    "            # scoreforfiles.append(float(combinedsegments[key][x]0))\n",
    "\n",
    "            # order=[]\n",
    "            # for key in MaxAggregation.keys():\n",
    "            #     l=MaxAggregation[key]\n",
    "            #     summ=[]\n",
    "            #     for val in l:\n",
    "            #         summ.append(val[0])\n",
    "            #     order.append(sum(summ))\n",
    "            \n",
    "            \n",
    "            # max_val=max(order)\n",
    "            # max_index=order.index(max_val)\n",
    "            # ClassPredicted=get_key(max_index)\n",
    "\n",
    "            # RSlistss=MaxAggregation[max_index]\n",
    "            # scoress=[]\n",
    "            # for s in RSlistss:\n",
    "            #     scoress.append(s[0])\n",
    "\n",
    "            # RS_CP=sum(scoress)/len(scoress)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Def Predicted Class and RS of Class HM\n",
    "def PredictionHM(dict):\n",
    "    d={}\n",
    "    for k,v in tqdm(dict.items()): #for each label\n",
    "        if len(dict[k]) == 0:\n",
    "            continue\n",
    "        d1={}\n",
    "        for i in range(len(dict[k])): #for each file in label\n",
    "            combinedsegments=segmentcombiner(dict[k][i])\n",
    "            key=list(combinedsegments.keys())[0]\n",
    "            order=[]\n",
    "            for kk in combinedsegments[key].keys():\n",
    "                l=combinedsegments[key][kk]\n",
    "                order.append(l)\n",
    "            max_val=max(order)\n",
    "            max_index=order.index(max_val)\n",
    "            ClassPredicted=get_key(max_index)\n",
    "\n",
    "            ll=(dict[k][i][key][max_index])\n",
    "            lll=[]\n",
    "            for score in ll:\n",
    "                lll.append(score[1][0][2])\n",
    "            avg=sum(lll)/len(ll)\n",
    "\n",
    "\n",
    "            RS_CP=float(avg)\n",
    "            d2={'ClassPredicted': ClassPredicted, 'RS_CP': RS_CP }\n",
    "            d1[key]=d2\n",
    "        d[k]=d1\n",
    "\n",
    "    return d\n",
    "\n",
    "            # \n",
    "            # scoreforfiles.append(float(combinedsegments[key][x]0))\n",
    "\n",
    "            # order=[]\n",
    "            # for key in MaxAggregation.keys():\n",
    "            #     l=MaxAggregation[key]\n",
    "            #     summ=[]\n",
    "            #     for val in l:\n",
    "            #         summ.append(val[0])\n",
    "            #     order.append(sum(summ))\n",
    "            \n",
    "            \n",
    "            # max_val=max(order)\n",
    "            # max_index=order.index(max_val)\n",
    "            # ClassPredicted=get_key(max_index)\n",
    "\n",
    "            # RSlistss=MaxAggregation[max_index]\n",
    "            # scoress=[]\n",
    "            # for s in RSlistss:\n",
    "            #     scoress.append(s[0])\n",
    "\n",
    "            # RS_CP=sum(scoress)/len(scoress)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb86eeef659344fab340af63dbf1c1ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'Automotive': 5.0, 'Books and Literature': 5.0, 'Business and Finance': 10.0, 'Education': 0.0, 'Events and Attractions': 40.0, 'Family and Relationships': 10.0, 'Food & Drink': 65.0, 'Hobbies & Interests': 0.0, 'Medical Health': 70.0, 'Music and Audio': 60.0, 'Pets': 0.0, 'Real Estate': 85.0, 'Religion & Spirituality': 0.0, 'Science': 0.0, 'Shopping': 5.0, 'Sports': 0.0, 'Style & Fashion': 100.0, 'Technology & Computing': 10.0, 'Television': 5.0, 'Travel': 10.0}, 24.0)\n"
     ]
    }
   ],
   "source": [
    "print(mAP(Relevance_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Def mAP\n",
    "def mAP(dic):\n",
    "    res=Prediction(dic)\n",
    "    d={}\n",
    "    mAP=[]\n",
    "    for k,v in res.items():\n",
    "        classes=[]\n",
    "        truth=[]\n",
    "\n",
    "        for kk,vv in res[k].items():\n",
    "            ClassPred=res[k][kk]['ClassPredicted']\n",
    "            if ClassPred==k:\n",
    "                classes.append(ClassPred)\n",
    "            truth.append(k)\n",
    "        precision=(len(classes)/len(truth))*100\n",
    "        mAP.append(precision)\n",
    "        d[k]=precision\n",
    "    mAPfinal=sum(mAP)/len(mAP)\n",
    "    return(d,mAPfinal)\n",
    "  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Relevance_dict['Automotive'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topksentences(dict):\n",
    "    d=defaultdict(list)\n",
    "    adwords=[]\n",
    "    texts=[]\n",
    "    scores=[]\n",
    "    for k,v in tqdm(dict.items()):#for each label\n",
    "        if len(dict[k]) == 0:\n",
    "            continue\n",
    "        scoreforfiles=[]\n",
    " \n",
    "        for i in range(len(dict[k])): #for each file in label\n",
    "            x=target_dict[k]\n",
    "            seg_rel=copy.deepcopy(dict[k][i])\n",
    "            filename=list(seg_rel.keys())[0]\n",
    "            defdict=seg_rel[filename]\n",
    "            segments=defdict[x]\n",
    "            # for count,seg1 in enumerate(segments):\n",
    "            #     if len(seg1)==0:\n",
    "            #         segments[count].append('Buffer')\n",
    "\n",
    "\n",
    "            for count,seg in enumerate(segments):\n",
    "                seg.append(filename)\n",
    "                seg.append(count)                \n",
    "                scoreforfiles.append(seg)\n",
    "        sort=sorted(scoreforfiles, key=lambda x: x[0], reverse=True)\n",
    "        Final=sort[0:20]\n",
    "        # print(Final)\n",
    "        \n",
    "        for items in Final:\n",
    "            index=materialID.index(items[3])\n",
    "            try:\n",
    "                items.append(dad[index][items[4]][items[1]])\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print(index,items[4],items[1])\n",
    "                # print(dad[index][items[4]][items[1]])\n",
    "                print(newnewmetalist[index][items[4]][items[1]])\n",
    "                # items.append(dad[index][items[4]][items[1]])\n",
    "                continue\n",
    "        # print(Final)\n",
    "        ff=[]\n",
    "        for f in Final:\n",
    "            dic={}\n",
    "            temp=str(f[0])\n",
    "            temp=temp.replace('tensor(', \"\")\n",
    "            temp=temp.replace(')', \"\")\n",
    "            dic['Adword']=k\n",
    "            dic['Text']=f[5]\n",
    "            dic['Score']=temp\n",
    "            \n",
    "            fff.append(dic)\n",
    "    \n",
    "        # d[k].extend(ff)\n",
    "    return fff\n",
    "    \n",
    "        \n",
    "\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(materialID.index('FILE_MAF_20210729T074455Z_GMO_00000000044309_01'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df2d59d9d1944bf3a279c157d19108f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dict_top20=topksentences(Relevance_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'DataFrame' has no attribute 'from_list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/mnt/data0/haskari/Comcast/Testing_NRS_Top1_Regular.ipynb Cell 48'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bsohrab.idav.ucdavis.edu/mnt/data0/haskari/Comcast/Testing_NRS_Top1_Regular.ipynb#ch0000047vscode-remote?line=0'>1</a>\u001b[0m df11\u001b[39m=\u001b[39mpd\u001b[39m.\u001b[39;49mDataFrame\u001b[39m.\u001b[39;49mfrom_list(dict_top20)\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'DataFrame' has no attribute 'from_list'"
     ]
    }
   ],
   "source": [
    "df11=pd.DataFrame.from_list(dict_top20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Automotive</th>\n",
       "      <th>Books and Literature</th>\n",
       "      <th>Business and Finance</th>\n",
       "      <th>Education</th>\n",
       "      <th>Events and Attractions</th>\n",
       "      <th>Family and Relationships</th>\n",
       "      <th>Food &amp; Drink</th>\n",
       "      <th>Hobbies &amp; Interests</th>\n",
       "      <th>Medical Health</th>\n",
       "      <th>Music and Audio</th>\n",
       "      <th>Pets</th>\n",
       "      <th>Real Estate</th>\n",
       "      <th>Religion &amp; Spirituality</th>\n",
       "      <th>Science</th>\n",
       "      <th>Shopping</th>\n",
       "      <th>Sports</th>\n",
       "      <th>Style &amp; Fashion</th>\n",
       "      <th>Technology &amp; Computing</th>\n",
       "      <th>Television</th>\n",
       "      <th>Travel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'Adword': 'Automotive', 'Text': 'the most suc...</td>\n",
       "      <td>{'Adword': 'Books and Literature', 'Text': 'fl...</td>\n",
       "      <td>{'Adword': 'Business and Finance', 'Text': 'an...</td>\n",
       "      <td>{'Adword': 'Education', 'Text': 'the grades th...</td>\n",
       "      <td>{'Adword': 'Events and Attractions', 'Text': '...</td>\n",
       "      <td>{'Adword': 'Family and Relationships', 'Text':...</td>\n",
       "      <td>{'Adword': 'Food &amp; Drink', 'Text': 'friday's e...</td>\n",
       "      <td>{'Adword': 'Hobbies &amp; Interests', 'Text': 'any...</td>\n",
       "      <td>{'Adword': 'Medical Health', 'Text': 'there ar...</td>\n",
       "      <td>{'Adword': 'Music and Audio', 'Text': 'anythin...</td>\n",
       "      <td>{'Adword': 'Pets', 'Text': 'my spare set of ca...</td>\n",
       "      <td>{'Adword': 'Real Estate', 'Text': '  as the ma...</td>\n",
       "      <td>{'Adword': 'Religion &amp; Spirituality', 'Text': ...</td>\n",
       "      <td>{'Adword': 'Science', 'Text': 'chandra the wor...</td>\n",
       "      <td>{'Adword': 'Shopping', 'Text': ' anything in t...</td>\n",
       "      <td>{'Adword': 'Sports', 'Text': 'talk about a who...</td>\n",
       "      <td>{'Adword': 'Style &amp; Fashion', 'Text': ''s\" fas...</td>\n",
       "      <td>{'Adword': 'Technology &amp; Computing', 'Text': '...</td>\n",
       "      <td>{'Adword': 'Television', 'Text': 'if i know an...</td>\n",
       "      <td>{'Adword': 'Travel', 'Text': ' itinerary reque...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'Adword': 'Automotive', 'Text': 'cb radio sta...</td>\n",
       "      <td>{'Adword': 'Books and Literature', 'Text': ' m...</td>\n",
       "      <td>{'Adword': 'Business and Finance', 'Text': 'uh...</td>\n",
       "      <td>{'Adword': 'Education', 'Text': ' why don't yo...</td>\n",
       "      <td>{'Adword': 'Events and Attractions', 'Text': '...</td>\n",
       "      <td>{'Adword': 'Family and Relationships', 'Text':...</td>\n",
       "      <td>{'Adword': 'Food &amp; Drink', 'Text': 'different ...</td>\n",
       "      <td>{'Adword': 'Hobbies &amp; Interests', 'Text': '  m...</td>\n",
       "      <td>{'Adword': 'Medical Health', 'Text': ' i want ...</td>\n",
       "      <td>{'Adword': 'Music and Audio', 'Text': 'camera ...</td>\n",
       "      <td>{'Adword': 'Pets', 'Text': 'oh the new tiffany...</td>\n",
       "      <td>{'Adword': 'Real Estate', 'Text': '  and real ...</td>\n",
       "      <td>{'Adword': 'Religion &amp; Spirituality', 'Text': ...</td>\n",
       "      <td>{'Adword': 'Science', 'Text': 'i know a scient...</td>\n",
       "      <td>{'Adword': 'Shopping', 'Text': ' what  do you ...</td>\n",
       "      <td>{'Adword': 'Sports', 'Text': ' what  some next...</td>\n",
       "      <td>{'Adword': 'Style &amp; Fashion', 'Text': ' moans ...</td>\n",
       "      <td>{'Adword': 'Technology &amp; Computing', 'Text': '...</td>\n",
       "      <td>{'Adword': 'Television', 'Text': ' so much of ...</td>\n",
       "      <td>{'Adword': 'Travel', 'Text': '  bucket list ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'Adword': 'Automotive', 'Text': 'it'll have a...</td>\n",
       "      <td>{'Adword': 'Books and Literature', 'Text': ' d...</td>\n",
       "      <td>{'Adword': 'Business and Finance', 'Text': 'i ...</td>\n",
       "      <td>{'Adword': 'Education', 'Text': ' there's boar...</td>\n",
       "      <td>{'Adword': 'Events and Attractions', 'Text': '...</td>\n",
       "      <td>{'Adword': 'Family and Relationships', 'Text':...</td>\n",
       "      <td>{'Adword': 'Food &amp; Drink', 'Text': 'different ...</td>\n",
       "      <td>{'Adword': 'Hobbies &amp; Interests', 'Text': ' so...</td>\n",
       "      <td>{'Adword': 'Medical Health', 'Text': ' your me...</td>\n",
       "      <td>{'Adword': 'Music and Audio', 'Text': '  sighs...</td>\n",
       "      <td>{'Adword': 'Pets', 'Text': 'and the furnishing...</td>\n",
       "      <td>{'Adword': 'Real Estate', 'Text': 'we just got...</td>\n",
       "      <td>{'Adword': 'Religion &amp; Spirituality', 'Text': ...</td>\n",
       "      <td>{'Adword': 'Science', 'Text': 'i'm sort of int...</td>\n",
       "      <td>{'Adword': 'Shopping', 'Text': '  sighs  what ...</td>\n",
       "      <td>{'Adword': 'Sports', 'Text': 'man we are athle...</td>\n",
       "      <td>{'Adword': 'Style &amp; Fashion', 'Text': 'at stak...</td>\n",
       "      <td>{'Adword': 'Technology &amp; Computing', 'Text': '...</td>\n",
       "      <td>{'Adword': 'Television', 'Text': 'the phone in...</td>\n",
       "      <td>{'Adword': 'Travel', 'Text': ' if you find som...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'Adword': 'Automotive', 'Text': ' engine 51 t...</td>\n",
       "      <td>{'Adword': 'Books and Literature', 'Text': 'i ...</td>\n",
       "      <td>{'Adword': 'Business and Finance', 'Text': 'wo...</td>\n",
       "      <td>{'Adword': 'Education', 'Text': ' it's your sc...</td>\n",
       "      <td>{'Adword': 'Events and Attractions', 'Text': '...</td>\n",
       "      <td>{'Adword': 'Family and Relationships', 'Text':...</td>\n",
       "      <td>{'Adword': 'Food &amp; Drink', 'Text': 'you must c...</td>\n",
       "      <td>{'Adword': 'Hobbies &amp; Interests', 'Text': 'the...</td>\n",
       "      <td>{'Adword': 'Medical Health', 'Text': ' you peo...</td>\n",
       "      <td>{'Adword': 'Music and Audio', 'Text': 'rock mu...</td>\n",
       "      <td>{'Adword': 'Pets', 'Text': 'i've got some shop...</td>\n",
       "      <td>{'Adword': 'Real Estate', 'Text': ' we sell re...</td>\n",
       "      <td>{'Adword': 'Religion &amp; Spirituality', 'Text': ...</td>\n",
       "      <td>{'Adword': 'Science', 'Text': ' you're the sci...</td>\n",
       "      <td>{'Adword': 'Shopping', 'Text': 'they have gift...</td>\n",
       "      <td>{'Adword': 'Sports', 'Text': 'and we go wrestl...</td>\n",
       "      <td>{'Adword': 'Style &amp; Fashion', 'Text': 'at stak...</td>\n",
       "      <td>{'Adword': 'Technology &amp; Computing', 'Text': '...</td>\n",
       "      <td>{'Adword': 'Television', 'Text': 'lost this se...</td>\n",
       "      <td>{'Adword': 'Travel', 'Text': 'we've got tahiti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'Adword': 'Automotive', 'Text': 'alarm sounds...</td>\n",
       "      <td>{'Adword': 'Books and Literature', 'Text': ' h...</td>\n",
       "      <td>{'Adword': 'Business and Finance', 'Text': 'i ...</td>\n",
       "      <td>{'Adword': 'Education', 'Text': ' i'm at belai...</td>\n",
       "      <td>{'Adword': 'Events and Attractions', 'Text': '...</td>\n",
       "      <td>{'Adword': 'Family and Relationships', 'Text':...</td>\n",
       "      <td>{'Adword': 'Food &amp; Drink', 'Text': ' in the cu...</td>\n",
       "      <td>{'Adword': 'Hobbies &amp; Interests', 'Text': ' wh...</td>\n",
       "      <td>{'Adword': 'Medical Health', 'Text': '  and  1...</td>\n",
       "      <td>{'Adword': 'Music and Audio', 'Text': 'somber ...</td>\n",
       "      <td>{'Adword': 'Pets', 'Text': 'so what do you hav...</td>\n",
       "      <td>{'Adword': 'Real Estate', 'Text': 'you can sel...</td>\n",
       "      <td>{'Adword': 'Religion &amp; Spirituality', 'Text': ...</td>\n",
       "      <td>{'Adword': 'Science', 'Text': 'except air and ...</td>\n",
       "      <td>{'Adword': 'Shopping', 'Text': ' like a restoc...</td>\n",
       "      <td>{'Adword': 'Sports', 'Text': 'we got jackets h...</td>\n",
       "      <td>{'Adword': 'Style &amp; Fashion', 'Text': 'at stak...</td>\n",
       "      <td>{'Adword': 'Technology &amp; Computing', 'Text': '...</td>\n",
       "      <td>{'Adword': 'Television', 'Text': '\" al housewi...</td>\n",
       "      <td>{'Adword': 'Travel', 'Text': 'cruise ships are...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Automotive  \\\n",
       "0  {'Adword': 'Automotive', 'Text': 'the most suc...   \n",
       "1  {'Adword': 'Automotive', 'Text': 'cb radio sta...   \n",
       "2  {'Adword': 'Automotive', 'Text': 'it'll have a...   \n",
       "3  {'Adword': 'Automotive', 'Text': ' engine 51 t...   \n",
       "4  {'Adword': 'Automotive', 'Text': 'alarm sounds...   \n",
       "\n",
       "                                Books and Literature  \\\n",
       "0  {'Adword': 'Books and Literature', 'Text': 'fl...   \n",
       "1  {'Adword': 'Books and Literature', 'Text': ' m...   \n",
       "2  {'Adword': 'Books and Literature', 'Text': ' d...   \n",
       "3  {'Adword': 'Books and Literature', 'Text': 'i ...   \n",
       "4  {'Adword': 'Books and Literature', 'Text': ' h...   \n",
       "\n",
       "                                Business and Finance  \\\n",
       "0  {'Adword': 'Business and Finance', 'Text': 'an...   \n",
       "1  {'Adword': 'Business and Finance', 'Text': 'uh...   \n",
       "2  {'Adword': 'Business and Finance', 'Text': 'i ...   \n",
       "3  {'Adword': 'Business and Finance', 'Text': 'wo...   \n",
       "4  {'Adword': 'Business and Finance', 'Text': 'i ...   \n",
       "\n",
       "                                           Education  \\\n",
       "0  {'Adword': 'Education', 'Text': 'the grades th...   \n",
       "1  {'Adword': 'Education', 'Text': ' why don't yo...   \n",
       "2  {'Adword': 'Education', 'Text': ' there's boar...   \n",
       "3  {'Adword': 'Education', 'Text': ' it's your sc...   \n",
       "4  {'Adword': 'Education', 'Text': ' i'm at belai...   \n",
       "\n",
       "                              Events and Attractions  \\\n",
       "0  {'Adword': 'Events and Attractions', 'Text': '...   \n",
       "1  {'Adword': 'Events and Attractions', 'Text': '...   \n",
       "2  {'Adword': 'Events and Attractions', 'Text': '...   \n",
       "3  {'Adword': 'Events and Attractions', 'Text': '...   \n",
       "4  {'Adword': 'Events and Attractions', 'Text': '...   \n",
       "\n",
       "                            Family and Relationships  \\\n",
       "0  {'Adword': 'Family and Relationships', 'Text':...   \n",
       "1  {'Adword': 'Family and Relationships', 'Text':...   \n",
       "2  {'Adword': 'Family and Relationships', 'Text':...   \n",
       "3  {'Adword': 'Family and Relationships', 'Text':...   \n",
       "4  {'Adword': 'Family and Relationships', 'Text':...   \n",
       "\n",
       "                                        Food & Drink  \\\n",
       "0  {'Adword': 'Food & Drink', 'Text': 'friday's e...   \n",
       "1  {'Adword': 'Food & Drink', 'Text': 'different ...   \n",
       "2  {'Adword': 'Food & Drink', 'Text': 'different ...   \n",
       "3  {'Adword': 'Food & Drink', 'Text': 'you must c...   \n",
       "4  {'Adword': 'Food & Drink', 'Text': ' in the cu...   \n",
       "\n",
       "                                 Hobbies & Interests  \\\n",
       "0  {'Adword': 'Hobbies & Interests', 'Text': 'any...   \n",
       "1  {'Adword': 'Hobbies & Interests', 'Text': '  m...   \n",
       "2  {'Adword': 'Hobbies & Interests', 'Text': ' so...   \n",
       "3  {'Adword': 'Hobbies & Interests', 'Text': 'the...   \n",
       "4  {'Adword': 'Hobbies & Interests', 'Text': ' wh...   \n",
       "\n",
       "                                      Medical Health  \\\n",
       "0  {'Adword': 'Medical Health', 'Text': 'there ar...   \n",
       "1  {'Adword': 'Medical Health', 'Text': ' i want ...   \n",
       "2  {'Adword': 'Medical Health', 'Text': ' your me...   \n",
       "3  {'Adword': 'Medical Health', 'Text': ' you peo...   \n",
       "4  {'Adword': 'Medical Health', 'Text': '  and  1...   \n",
       "\n",
       "                                     Music and Audio  \\\n",
       "0  {'Adword': 'Music and Audio', 'Text': 'anythin...   \n",
       "1  {'Adword': 'Music and Audio', 'Text': 'camera ...   \n",
       "2  {'Adword': 'Music and Audio', 'Text': '  sighs...   \n",
       "3  {'Adword': 'Music and Audio', 'Text': 'rock mu...   \n",
       "4  {'Adword': 'Music and Audio', 'Text': 'somber ...   \n",
       "\n",
       "                                                Pets  \\\n",
       "0  {'Adword': 'Pets', 'Text': 'my spare set of ca...   \n",
       "1  {'Adword': 'Pets', 'Text': 'oh the new tiffany...   \n",
       "2  {'Adword': 'Pets', 'Text': 'and the furnishing...   \n",
       "3  {'Adword': 'Pets', 'Text': 'i've got some shop...   \n",
       "4  {'Adword': 'Pets', 'Text': 'so what do you hav...   \n",
       "\n",
       "                                         Real Estate  \\\n",
       "0  {'Adword': 'Real Estate', 'Text': '  as the ma...   \n",
       "1  {'Adword': 'Real Estate', 'Text': '  and real ...   \n",
       "2  {'Adword': 'Real Estate', 'Text': 'we just got...   \n",
       "3  {'Adword': 'Real Estate', 'Text': ' we sell re...   \n",
       "4  {'Adword': 'Real Estate', 'Text': 'you can sel...   \n",
       "\n",
       "                             Religion & Spirituality  \\\n",
       "0  {'Adword': 'Religion & Spirituality', 'Text': ...   \n",
       "1  {'Adword': 'Religion & Spirituality', 'Text': ...   \n",
       "2  {'Adword': 'Religion & Spirituality', 'Text': ...   \n",
       "3  {'Adword': 'Religion & Spirituality', 'Text': ...   \n",
       "4  {'Adword': 'Religion & Spirituality', 'Text': ...   \n",
       "\n",
       "                                             Science  \\\n",
       "0  {'Adword': 'Science', 'Text': 'chandra the wor...   \n",
       "1  {'Adword': 'Science', 'Text': 'i know a scient...   \n",
       "2  {'Adword': 'Science', 'Text': 'i'm sort of int...   \n",
       "3  {'Adword': 'Science', 'Text': ' you're the sci...   \n",
       "4  {'Adword': 'Science', 'Text': 'except air and ...   \n",
       "\n",
       "                                            Shopping  \\\n",
       "0  {'Adword': 'Shopping', 'Text': ' anything in t...   \n",
       "1  {'Adword': 'Shopping', 'Text': ' what  do you ...   \n",
       "2  {'Adword': 'Shopping', 'Text': '  sighs  what ...   \n",
       "3  {'Adword': 'Shopping', 'Text': 'they have gift...   \n",
       "4  {'Adword': 'Shopping', 'Text': ' like a restoc...   \n",
       "\n",
       "                                              Sports  \\\n",
       "0  {'Adword': 'Sports', 'Text': 'talk about a who...   \n",
       "1  {'Adword': 'Sports', 'Text': ' what  some next...   \n",
       "2  {'Adword': 'Sports', 'Text': 'man we are athle...   \n",
       "3  {'Adword': 'Sports', 'Text': 'and we go wrestl...   \n",
       "4  {'Adword': 'Sports', 'Text': 'we got jackets h...   \n",
       "\n",
       "                                     Style & Fashion  \\\n",
       "0  {'Adword': 'Style & Fashion', 'Text': ''s\" fas...   \n",
       "1  {'Adword': 'Style & Fashion', 'Text': ' moans ...   \n",
       "2  {'Adword': 'Style & Fashion', 'Text': 'at stak...   \n",
       "3  {'Adword': 'Style & Fashion', 'Text': 'at stak...   \n",
       "4  {'Adword': 'Style & Fashion', 'Text': 'at stak...   \n",
       "\n",
       "                              Technology & Computing  \\\n",
       "0  {'Adword': 'Technology & Computing', 'Text': '...   \n",
       "1  {'Adword': 'Technology & Computing', 'Text': '...   \n",
       "2  {'Adword': 'Technology & Computing', 'Text': '...   \n",
       "3  {'Adword': 'Technology & Computing', 'Text': '...   \n",
       "4  {'Adword': 'Technology & Computing', 'Text': '...   \n",
       "\n",
       "                                          Television  \\\n",
       "0  {'Adword': 'Television', 'Text': 'if i know an...   \n",
       "1  {'Adword': 'Television', 'Text': ' so much of ...   \n",
       "2  {'Adword': 'Television', 'Text': 'the phone in...   \n",
       "3  {'Adword': 'Television', 'Text': 'lost this se...   \n",
       "4  {'Adword': 'Television', 'Text': '\" al housewi...   \n",
       "\n",
       "                                              Travel  \n",
       "0  {'Adword': 'Travel', 'Text': ' itinerary reque...  \n",
       "1  {'Adword': 'Travel', 'Text': '  bucket list ch...  \n",
       "2  {'Adword': 'Travel', 'Text': ' if you find som...  \n",
       "3  {'Adword': 'Travel', 'Text': 'we've got tahiti...  \n",
       "4  {'Adword': 'Travel', 'Text': 'cruise ships are...  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df11.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df11.to_csv(\"Top20Sentences.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4f8fa3e926face00369008f823e0a800506eaa9d6c726ba0fbe6c8d0f6896eaa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
